# ğŸ—£ï¸ Madellang - The RT Translator and language tutor

A **real-time voice translation** web application designed for ultra-low latency communication. This app enables seamless voice translation by streaming audio to a server, translating speech into a selected language, and streaming the translated voice back to usersâ€”all within a simple, single-screen interface.

## ğŸŒŸ Features  
- **ğŸ“¡ WebSocket-based Real-Time Streaming** â€“ Ensures low-latency communication.  
- **ğŸ“± QR Code for Room Access** â€“ Instantly share room links with others.  
- **ğŸ™ï¸ Live Speech-to-Text + Translation + Text-to-Speech** â€“ Supports multiple languages.  
- **ğŸŒ Cloud API & Local AI Support** â€“ Choose between cloud-based translation (OpenAI Whisper, Google, DeepL) or an offline model (Whisper, Vosk, Coqui TTS).  
- **ğŸ”„ Bidirectional Voice Streaming** â€“ Speak and listen simultaneously in a conversation.  
- **ğŸ–¥ï¸ Minimalist UI** â€“ Simple interface with a **Start** button, language dropdown, and QR code for easy access.  

## ğŸ—ï¸ Architecture Overview  
1. **Frontend (Web App)**  
   - Generates **QR codes** for room sharing.  
   - Establishes **WebSocket connections** to the server.  
   - Streams **audio** to the server for real-time translation.  
   - Plays back the translated speech in the selected language.  

2. **Backend (Server)**  
   - Handles **WebSocket communication** for audio streaming.  
   - Processes speech using either a **cloud API** (e.g., Google Speech-to-Text) or a **local AI model** (e.g., Whisper).  
   - Translates text to the chosen **target language**.  
   - Converts translated text back into **speech** and streams it to clients.  

## ğŸ› ï¸ Tech Stack  
- **Frontend:** React (or Svelte) + WebRTC/WebSockets  
- **Backend:** Node.js (Express/Fastify) or Python (FastAPI)  
- **AI Services:**  
  - **Cloud APIs:** OpenAI Whisper, Google Cloud Speech, DeepL  
  - **Local Models:** Whisper (STT), Coqui TTS, Vosk (offline STT)  
- **Streaming:** WebRTC or WebSockets for real-time audio transmission  

## ğŸš€ Getting Started  

### 1ï¸âƒ£ Clone the Repository  
```sh
git clone https://github.com/yourusername/live-voice-translator.git
cd live-voice-translator
```

### 2ï¸âƒ£ Install Dependencies
Frontend

```sh
cd frontend
npm install
```

Backend
```sh
cd backend
npm install
```

(or use Python pip install -r requirements.txt if using FastAPI instead of Node.js)

### 3ï¸âƒ£ Run the Application
Start Backend Server
```sh
cd backend
npm start
```
(or python main.py for FastAPI implementation)

Start Frontend
```sh
cd frontend
npm run dev
```

### 4ï¸âƒ£ Open the Web App

    Go to http://localhost:3000 (or the appropriate port).
    Click Start, scan the QR code, and begin streaming live translations!

### Configuration

    .env file for API keys (e.g., Google, OpenAI).
    Configure local AI model paths if using an offline model.

### ğŸ“Œ Roadmap

> âœ… MVP with basic real-time translation
> ğŸ”² Improve local AI model support
> ğŸ”² Add multi-user voice channels
> ğŸ”² Enhance mobile support & PWA integration

### ğŸ¤ Contributing

Contributions are welcome! Fork the repo, make your changes, and submit a PR.

### ğŸ“œ License

MIT License Â© 2025 Piotr Slupski

ğŸš€ Enjoy real-time voice translation with low latency and seamless streaming!


---

This **README.md** provides a clear overview of the project, setup instructions, tech stack, and roadmap. Let me know if youâ€™d like to customize anything! ğŸš€

